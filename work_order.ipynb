{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Hh0ifohsspebKntcuuwqlhjMl9-i0ouT",
      "authorship_tag": "ABX9TyP3LjICl4du8hwM8+B4PAph",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asare-Obed/WorkOrder-Automation/blob/main/work_order.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INSTALLING AND IMPORTING MODULES**"
      ],
      "metadata": {
        "id": "a_qTWQAK6_N2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install docxtpl"
      ],
      "metadata": {
        "id": "wyL8cCZl5ONj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unpQnHDK2wzM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from docxtpl import DocxTemplate\n",
        "from datetime import datetime\n",
        "from collections import defaultdict\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **USER CONFIGURATION AND DATA PATHS**"
      ],
      "metadata": {
        "id": "ayGc_qzM66Yr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WORK_PLAN_FILE = \"/content/drive/MyDrive/Work Order_May22-June19_2025.xlsx\"\n",
        "LOOKUP_FILE = \"/content/drive/MyDrive/KoboTestTable for WO Automation.xlsx\"\n",
        "TEMPLATE_MAP = {\n",
        "    \"Planting\": \"/content/drive/MyDrive/Planting-WorkOrderTemplate.docx\",\n",
        "    \"Pitting\": \"/content/drive/MyDrive/Establishment_Holing-WorkOrderTemplate.docx\",\n",
        "    \"Establishment Clearing\": \"/content/drive/MyDrive/Establishment_Clearing-WorkOrderTemplate.docx\"}\n",
        "OUTPUT_FOLDER = \"/content/drive/MyDrive/rbgh_automations/generated_workorder\"\n",
        "os.makedirs(OUTPUT_FOLDER, exist_ok=True)"
      ],
      "metadata": {
        "id": "tpAKqY9B4wtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(WORK_PLAN_FILE)"
      ],
      "metadata": {
        "id": "NuCSuWLr48Gf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns = df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "print(df.columns.tolist())"
      ],
      "metadata": {
        "id": "l7Wfl8_C6NXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4235ed-4518-492e-cf68-ba164e5004d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['s/n', 'week_number', 'date', 'section', 'operation', 'work_location', 'assigned_team', 'work_quantity_(ha)', 'forester_name', 'team_leader', 'work_order_id']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['work_order_id'].notna()]"
      ],
      "metadata": {
        "id": "hf0mrOw4YN7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['work_order_id'] = df['work_order_id'].astype(str).str.strip().str.lower()\n",
        "df['work_order_id'] = df['work_order_id'].str.replace(\"wo-\", \"wo_\")  # Normalize to match lookup"
      ],
      "metadata": {
        "id": "PAyOiEun1zh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**LOAD KOBO LOOKUP TABLE**"
      ],
      "metadata": {
        "id": "wGzEEP1ZixFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**If the data has already been cleaned manually or it's a single sheet in the spreadsheet then this code block will be used**"
      ],
      "metadata": {
        "id": "Hhh5P6-2C_ni"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "lookup_df = pd.read_excel(LOOKUP_FILE)\n",
        "lookup_df.columns = lookup_df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "print(lookup_df.columns.tolist())\n",
        "lookup_dict = (\n",
        "    lookup_df\n",
        "    .groupby(\"work_order_id\")\n",
        "    .apply(lambda g: g.to_dict(orient=\"records\"))\n",
        "    .to_dict()\n",
        ")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "onI5ZreSDQPn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These Kobo exports typically contain:\n",
        "* A main sheet with form submissions (each row = one record)\n",
        "* One or more sub-sheets for repeat groups (like worker details, plots, etc.)\n",
        "\n",
        "So if your kobo data has a similar structure then this should clean and restructure the tables in a single table.\n",
        "\n",
        "In this code the lookup file contains the kobo data file filled by Silviculture for their daily input per worker per activity."
      ],
      "metadata": {
        "id": "5zEdM2yc-vmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load all sheets\n",
        "kobo_file = pd.read_excel(LOOKUP_FILE, sheet_name=None)\n",
        "\n",
        "# Extract main sheet and repeat group\n",
        "main_df = list(kobo_file.values())[0]\n",
        "repeat_df = list(kobo_file.values())[1]  # change index if needed\n",
        "\n",
        "# Standardize column names\n",
        "main_df.columns = main_df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "repeat_df.columns = repeat_df.columns.str.strip().str.lower().str.replace(\" \", \"_\")\n",
        "print(\"Main_df_columns=\",main_df.columns.tolist())\n",
        "print(\"Repeat_df_columns=\",repeat_df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGZY5GM4-lwg",
        "outputId": "4b6c4a9f-9945-4b5f-8cb1-e01dbd0ac04f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Main_df_columns= ['qc_attempt', 'date_of_qc', 'work_order_number', 'work_order_id', 'start_date_of_activity', 'end_date_of_activity', 'technical_officer', 'qc_officer', 'forest_reserve', 'compartment_id', 'sub-compartment', 'plot_number', 'gps_point', '_gps_point_latitude', '_gps_point_longitude', '_gps_point_altitude', '_gps_point_precision', 'land_cover', 'photo_north', 'photo_north_url', 'photo_east', 'photo_east_url', 'photo_south', 'photo_south_url', 'photo_west', 'photo_west_url', '_id', '_uuid', '_submission_time', '_validation_status', '_notes', '_status', '_submitted_by', '__version__', '_tags', '_index']\n",
            "Repeat_df_columns= ['worker_name', 'activity_id', 'activity', 'work_quantity_ha', 'work_quantity_m', 'slashing/bush_clearance_height_of_weeds_</=_15cm', 'slashing/bush_clearing_completeness', 'all_weeds_treated', 'marking_and_pitting_-_correct_spacing', 'number_of_pits', 'number_of_pits_with_unfirmed_soil_tilth', 'number_of_pits_with_niche_depth_and_width_>/=_30cm', 'all_large_debris_stones_removed', 'number_of_standing_invasive_trees', 'herbicide_effectivity', 'qc_status_001', 'qc_status:_${qc_status_001}', 'qc_status_002', 'qc_status:_${qc_status_002}', 'comments', 'slash/bush_clearance_height_of_weeds_</=_15cm', 'spacing_compliance_(3x3m_Â±10cm)?', '_index', '_parent_table_name', '_parent_index', '_submission__id', '_submission__uuid', '_submission__submission_time', '_submission__validation_status', '_submission__notes', '_submission__status', '_submission__submitted_by', '_submission___version__', '_submission__tags']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge based on _index from main table and parent_index from repeat table\n",
        "lookup_df = repeat_df.merge(\n",
        "    main_df,\n",
        "    left_on='_parent_index',\n",
        "    right_on='_index',\n",
        "    how='left'\n",
        ")"
      ],
      "metadata": {
        "id": "Be-CIQxKCcML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lookup_df['work_order_id'] = lookup_df['work_order_id'].astype(str).str.strip().str.lower()\n",
        "lookup_df['work_order_id'] = lookup_df['work_order_id'].str.replace(\"wo-\", \"wo_\")  # Normalize to match work plan"
      ],
      "metadata": {
        "id": "hTH8Fv1ixfMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this portion to check the merged sheets."
      ],
      "metadata": {
        "id": "9fPuGkHrTSqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output_path = os.path.join(OUTPUT_FOLDER, \"merged_lookup_export2.xlsx\")\n",
        "lookup_df.to_excel(output_path, index=False)\n",
        "print(f\"âœ… Exported to {output_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HE1FMZQR9In",
        "outputId": "59a664f2-89df-4a32-a86f-6fb88d2b8860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Exported to /content/drive/MyDrive/rbgh_automations/generated_workorder/merged_lookup_export2.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now build lookup_dict grouped by wo_id\n",
        "lookup_dict = (\n",
        "    lookup_df\n",
        "    .dropna(subset=['work_order_id'])  # ensure WO ID is available\n",
        "    .groupby(\"work_order_id\")\n",
        "    .apply(lambda g: g.to_dict(orient=\"records\"))\n",
        "    .to_dict()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGCcUf9FDfcd",
        "outputId": "3a7f087d-41c3-45e4-8b03-d7b92df790e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1966069555.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  .apply(lambda g: g.to_dict(orient=\"records\"))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"WO IDs found in work plan:\", df['work_order_id'].unique())\n",
        "print(\"WO IDs found in lookup dict:\", list(lookup_dict.keys())[:5], \"...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDSmLn1kySmk",
        "outputId": "6afb31ab-54cb-4a41-bb56-350ab8e08a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WO IDs found in work plan: ['wo_4' 'wo_5' 'wo_6' 'wo_7' 'wo_8' 'wo_9' 'wo_10' 'wo_11' 'wo_12' 'wo_3'\n",
            " 'wo_13' 'wo_14' 'wo_15']\n",
            "WO IDs found in lookup dict: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5'] ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "for wo_id, entries in list(lookup_dict.items())[:3]:  # show first 3 WO IDs\n",
        "    print(f\"\\nWork Order ID: {wo_id}\")\n",
        "    for entry in entries:\n",
        "        pprint(entry)\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "opnanjZTy-1U"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MbY-kdcBRCx2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GROUP BY WORK ORDER ID"
      ],
      "metadata": {
        "id": "edzGMpHT1dPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for wo_id, group in df.groupby(\"work_order_id\"):\n",
        "    row = group.iloc[0]\n",
        "    activity = row['operation'].strip()\n",
        "\n",
        "    # Pick correct template\n",
        "    matched_template = None\n",
        "    for key in TEMPLATE_MAP:\n",
        "        if key.lower() in activity.lower():\n",
        "            matched_template = TEMPLATE_MAP[key]\n",
        "            break\n",
        "\n",
        "    if not matched_template or not os.path.exists(matched_template):\n",
        "        print(f\"âš ï¸ No template found for activity: {activity}, WO ID: {wo_id}\")\n",
        "        continue\n",
        "\n",
        "    print(f\"ðŸ”Ž Attempting lookup with key: {wo_id}\")\n",
        "    print(f\"ðŸ”Ž Available keys: {list(lookup_dict.keys())[:5]}...\")  # only show first few\n",
        "\n",
        "    workers_info = lookup_dict.get(wo_id, [])\n",
        "    print(f\"ðŸ§© Matching WO ID: {wo_id} â†’ Found {len(workers_info)} workers\")\n",
        "\n",
        "    if not workers_info:\n",
        "        print(f\"  âš ï¸ Skipping {wo_id} (no worker data)\")\n",
        "        continue\n",
        "\n",
        "    for person in workers_info:\n",
        "        doc = DocxTemplate(matched_template)\n",
        "\n",
        "        issue_date = row['date']\n",
        "        due_date = group['date'].max()\n",
        "\n",
        "        target_areas = []\n",
        "        for _, r in group.iterrows():\n",
        "            plot = r['work_location']\n",
        "            target_areas.append({\n",
        "                \"reserve\": \"Chai River\",\n",
        "                \"compartment\": plot[:2],\n",
        "                \"sub_compartment\": plot,\n",
        "                \"plot_no\": plot,\n",
        "                \"area_ha\": r['work_quantity_(ha)']\n",
        "            })\n",
        "\n",
        "        context = {\n",
        "            \"worker\": person.get(\"worker\", \"Unnamed\"),\n",
        "            \"activity\": activity,\n",
        "            \"work_order_no\": wo_id.upper().replace(\"_\", \"-\"),\n",
        "            \"date_issued\": issue_date.strftime(\"%d/%m/%Y\"),\n",
        "            \"due_date\": due_date.strftime(\"%d/%m/%Y\"),\n",
        "            \"technical_officer\": row.get(\"forester_name\", \"John Kodua\"),\n",
        "            \"target_areas\": target_areas,\n",
        "            \"activity_id\": person.get(\"activity_id\", \"UNK\"),\n",
        "            \"mandays_ha\": person.get(\"mandays_per_ha\", \"1.0\"),\n",
        "            \"rate\": person.get(\"rate\", \"0.51\"),\n",
        "            \"total_amount\": person.get(\"amount\", \"Auto\"),\n",
        "            \"qc_result\": person.get(\"qc_result\", \"Pass\"),\n",
        "            \"total_seedlings\": person.get(\"seedlings\", \"1945\"),\n",
        "        }\n",
        "\n",
        "        doc.render(context)\n",
        "\n",
        "        # Format filename: WOID_Date_WorkerName.docx\n",
        "        formatted_date = due_date.strftime(\"%Y-%m-%d\")\n",
        "        worker_name = person.get(\"worker\", \"Unnamed\").lower().replace(\" \", \"_\")\n",
        "        filename = f\"{wo_id.upper()}_{worker_name}_{formatted_date}.docx\"\n",
        "        output_docx = os.path.join(OUTPUT_FOLDER, filename)\n",
        "        doc.save(output_docx)\n",
        "\n",
        "        # Optional: Convert to PDF if needed\n",
        "        #try:\n",
        "            #import shutil\n",
        "            #if shutil.which(\"libreoffice\"):\n",
        "                #import subprocess\n",
        "                #subprocess.run([\n",
        "                    #\"libreoffice\", \"--headless\", \"--convert-to\", \"pdf\", output_path, \"--outdir\", OUTPUT_FOLDER\n",
        "                #])\n",
        "            #else:\n",
        "                #print(f\"âš ï¸ LibreOffice not found. Skipping PDF export for {filename}\")\n",
        "        #except Exception as e:\n",
        "            #print(f\"âŒ PDF export error for {filename}: {e}\")\n",
        "\n",
        "print(\"âœ… Work orders generated.\")\n"
      ],
      "metadata": {
        "id": "Nt9V9gvfRjZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42f09ff2-9306-428a-df83-bb451667f415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”Ž Attempting lookup with key: wo_10\n",
            "ðŸ”Ž Available keys: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5']...\n",
            "ðŸ§© Matching WO ID: wo_10 â†’ Found 12 workers\n",
            "ðŸ”Ž Attempting lookup with key: wo_11\n",
            "ðŸ”Ž Available keys: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5']...\n",
            "ðŸ§© Matching WO ID: wo_11 â†’ Found 7 workers\n",
            "ðŸ”Ž Attempting lookup with key: wo_12\n",
            "ðŸ”Ž Available keys: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5']...\n",
            "ðŸ§© Matching WO ID: wo_12 â†’ Found 0 workers\n",
            "  âš ï¸ Skipping wo_12 (no worker data)\n",
            "ðŸ”Ž Attempting lookup with key: wo_13\n",
            "ðŸ”Ž Available keys: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5']...\n",
            "ðŸ§© Matching WO ID: wo_13 â†’ Found 0 workers\n",
            "  âš ï¸ Skipping wo_13 (no worker data)\n",
            "ðŸ”Ž Attempting lookup with key: wo_14\n",
            "ðŸ”Ž Available keys: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5']...\n",
            "ðŸ§© Matching WO ID: wo_14 â†’ Found 11 workers\n",
            "ðŸ”Ž Attempting lookup with key: wo_15\n",
            "ðŸ”Ž Available keys: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5']...\n",
            "ðŸ§© Matching WO ID: wo_15 â†’ Found 0 workers\n",
            "  âš ï¸ Skipping wo_15 (no worker data)\n",
            "ðŸ”Ž Attempting lookup with key: wo_3\n",
            "ðŸ”Ž Available keys: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5']...\n",
            "ðŸ§© Matching WO ID: wo_3 â†’ Found 1 workers\n",
            "ðŸ”Ž Attempting lookup with key: wo_4\n",
            "ðŸ”Ž Available keys: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5']...\n",
            "ðŸ§© Matching WO ID: wo_4 â†’ Found 0 workers\n",
            "  âš ï¸ Skipping wo_4 (no worker data)\n",
            "ðŸ”Ž Attempting lookup with key: wo_5\n",
            "ðŸ”Ž Available keys: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5']...\n",
            "ðŸ§© Matching WO ID: wo_5 â†’ Found 4 workers\n",
            "ðŸ”Ž Attempting lookup with key: wo_6\n",
            "ðŸ”Ž Available keys: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5']...\n",
            "ðŸ§© Matching WO ID: wo_6 â†’ Found 4 workers\n",
            "ðŸ”Ž Attempting lookup with key: wo_7\n",
            "ðŸ”Ž Available keys: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5']...\n",
            "ðŸ§© Matching WO ID: wo_7 â†’ Found 6 workers\n",
            "ðŸ”Ž Attempting lookup with key: wo_8\n",
            "ðŸ”Ž Available keys: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5']...\n",
            "ðŸ§© Matching WO ID: wo_8 â†’ Found 11 workers\n",
            "ðŸ”Ž Attempting lookup with key: wo_9\n",
            "ðŸ”Ž Available keys: ['wo_10', 'wo_11', 'wo_14', 'wo_3', 'wo_5']...\n",
            "ðŸ§© Matching WO ID: wo_9 â†’ Found 7 workers\n",
            "âœ… Work orders generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i-J3mGkS2OXi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}